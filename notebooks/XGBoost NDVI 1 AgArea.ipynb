{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b90527a",
   "metadata": {},
   "source": [
    "# Timeseries and met data based on paper that uses XGBoost\n",
    "\n",
    "https://www.mdpi.com/2072-4292/13/6/1147/pdf\n",
    "\n",
    "https://www.tandfonline.com/doi/full/10.1080/17538947.2020.1808718"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e033c56a",
   "metadata": {},
   "source": [
    "The date of this record can be truncated to the month, i.e. this record is for 2015-05. For this month;\n",
    "- **CHIRPS_SPI_actual** is the actual SPI for the month 2015-05 relative to all May months 1984 through 2021. It is available for the month before. So I can use it.\n",
    "- **MIXED_SPI** is the SPI for the month 2015-05 using the first **12 days from CHIRPS and the rest of the month from the mean seasonal forecast**; taking a weighted mean of the respective SPIs. The idea is this is the value we'd be able to use in production if we ran production at the end of each month\n",
    "- **FORECAST_SPI_{ii}** is the SPI based on the ensemble mean for 1 through six months in advance, i.e., in this case, for 2015-06, ..., 2015-11 (e: and this forecast was made on 2015-05-13. So each record has the next 6 months)\n",
    "- the **FORECAST_SPI** values are relative to all May forecasts 1993-2021, so the May forecast for July is relative all May forecasts for July, but not the June forecasts for July\n",
    "- there are sometimes when the SPI is inf  because all forecast data is 0. But inf can't into JSON so **I've filled in with the value 999. - so we'll need to do a data cleaning step before prediction**\n",
    "- **NDVI** is the mean of the whole months. If it says 2015-05-01 it means that it is the mean ndvi for the month 2015-05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6d51c",
   "metadata": {},
   "source": [
    "To be sure I don't have a data leakeage, let's study each feature:\n",
    "For each date time d (for example d is August) I assume d is truncated by month and ignore the day.\n",
    "Actually a better day would be to put last day of the month:\n",
    "- d is August (xxxx-08-01)\n",
    "- month_ndvi_mean: is the mean of whole August NDVI\n",
    "- mixed_spi: first 12 days of chirps, rest of forecast for all August\n",
    "- forecast_spi: mean for 1..6 months in advance (sept, oct, nov...)\n",
    "- chirps_actual: i cannot use this for training, because I don't have this info in production (or I can use it but it is not the same as mixed_spi)\n",
    "\n",
    "- If we run in production at the end of each month I'm using current month forecasted_spi so I cannot precit 7 months, but only 6 months\n",
    "\n",
    "### Missing values:\n",
    "Gotta take care of missing values, because otherwise the targets are not going to be realistic. If I shift after droping NaNs I can have a target that is for N months ahead but it shouldn't\n",
    "\n",
    "\n",
    "### Test set\n",
    "\n",
    "I'm leaving 21 points for the test set. So I can have 21-7 total predictions for each of the 7 models (one per month)\n",
    "\n",
    "\n",
    "### Model Types\n",
    "- We can train 7 models for the same input row\n",
    "- Or we can train 7 models but based on data predicted by previous model (it's like using one single model)\n",
    "    - The train can be done only for real data (current_ndiv, mixed_spi)\n",
    "    - But the the prediction I can use for current_ndvi the pred for previous month and instead of mixed spi the forecast_spi_1...7\n",
    "    \n",
    "# Baseline vs NDVI vs SM\n",
    "- Baseline model using only current and forecast_spi\n",
    "- NDVI adding ndvi derivatives\n",
    "- SM adding sm derivatives.\n",
    "\n",
    "Each of them trained in the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe77766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869418c2-1a03-4808-82b3-b977defc87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import httpx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from shapely import geometry\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21562853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tete_aga = 2179"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b910999-3ab4-4edc-9d5a-8c24601e38eb",
   "metadata": {},
   "source": [
    "# API Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac181a62-5d07-46b6-bd8d-f56419f7ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://localhost:8081/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3c618-8765-4366-a420-315d4b13b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpx.Client(base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4fdee-e8f9-4652-82fa-65cc85ec548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = client.post(\n",
    "    \"auth/token\",\n",
    "    data={\"username\": \"fran.dorr@gmail.com\", \"password\": \"fran123\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8579a-1e8f-44ef-9f64-57d97d2b8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = json.loads(r.text)[\"access_token\"]\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3989414-2d25-4d8b-aa9f-07426b36bf91",
   "metadata": {},
   "source": [
    "# Get agricultural areas geoms from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298df819-d44f-4b43-a7f2-b9c67c003113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = client.get(\"aoi/\", params=dict(id=tete_aga), headers=headers)\n",
    "res = json.loads(r.text)\n",
    "polygons = geometry.shape(res[\"features\"][0][\"geometry\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a134e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bbox for all the ag areas\n",
    "box = polygons.bounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5293bd6-f5d3-4758-8735-7e80074335d0",
   "metadata": {},
   "source": [
    "# Get Events from DB \n",
    "- Date range from 2019 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7722d23-d787-42b5-b9fa-34260117ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = \"1985-01-02\"\n",
    "end_datetime = \"2022-08-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf13b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = client.get(\n",
    "        \"events/\",\n",
    "        params=dict(\n",
    "            aoi_id=tete_aga,\n",
    "            start_datetime=start_datetime,\n",
    "            end_datetime=end_datetime,\n",
    "            limit=10000,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=60,\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aga_results = json.loads(r.text)[\"events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a833948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def get_keyed_values(results, label, keyed_value, new_col):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.labels = df.labels.map(lambda x: x[0])\n",
    "    df = df[df.labels == label]\n",
    "    df[new_col] = df.keyed_values.apply(lambda x: x.get(keyed_value))\n",
    "    df = df.drop_duplicates(subset=[\"aoi_id\", \"datetime\"]).dropna()\n",
    "    df.datetime = pd.to_datetime(df.datetime)\n",
    "    \n",
    "    \n",
    "    if keyed_value == \"FORECAST_SPI\":\n",
    "        months_df = df[new_col].apply(pd.Series)\n",
    "        months_df.columns = [f\"{new_col}_1\", f\"{new_col}_2\",\n",
    "                             f\"{new_col}_3\", f\"{new_col}_4\",\n",
    "                             f\"{new_col}_5\", f\"{new_col}_6\"]\n",
    "        df = pd.concat([df.drop([new_col], axis=1), months_df], axis=1)\n",
    "    \n",
    "        df.index = df[\"datetime\"]\n",
    "        \n",
    "    elif keyed_value == \"mean_value\":\n",
    "        df = df.groupby([\"datetime\"]).mean().resample(\"MS\").mean()\n",
    "        #df.index = df.index.map(lambda x: x.replace(day=1))\n",
    "      \n",
    "    else:\n",
    "        df.index = df[\"datetime\"]\n",
    "        \n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = get_keyed_values(aga_results, \"ndvi\", \"mean_value\", \"month_ndvi_mean\")\n",
    "sm = get_keyed_values(aga_results, \"soil_moisture\", \"mean_value\", \"month_sm_mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sm.dropna(subset=[\"month_sm_mean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_spi = get_keyed_values(aga_results, \"total_precipitation\", \"FORECAST_SPI\", \"forecast_spi\")\n",
    "mixed_spi = get_keyed_values(aga_results, \"total_precipitation\", \"MIXED_SPI\", \"mixed_spi\")\n",
    "chirps_actual = get_keyed_values(aga_results, \"total_precipitation\", \"CHIRPS_SPI_actual\", \"chirps_actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7461d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sm.dropna(subset=[\"month_sm_mean\"])\n",
    "ndvi[\"month_ndvi_mean\"] = ndvi[\"month_ndvi_mean\"].interpolate() \n",
    "ndvi[\"one_year_ndvi\"] = ndvi[\"month_ndvi_mean\"].shift(11).interpolate() \n",
    "ndvi[\"one_year_ndvi_adj_left\"] = ndvi[\"month_ndvi_mean\"].shift(12).interpolate() \n",
    "ndvi[\"one_year_ndvi_adj_right\"] = ndvi[\"month_ndvi_mean\"].shift(10).interpolate() \n",
    "\n",
    "ndvi[\"one_year_ndvi_diff_left\"] = ndvi[\"one_year_ndvi\"]-ndvi[\"one_year_ndvi_adj_left\"]\n",
    "ndvi[\"one_year_ndvi_diff_right\"] = ndvi[\"one_year_ndvi\"]-ndvi[\"one_year_ndvi_adj_right\"]\n",
    "\n",
    "ndvi[\"one_year_ndvi_ratio_left\"] = ndvi[\"one_year_ndvi_adj_left\"] / ndvi[\"one_year_ndvi\"]\n",
    "ndvi[\"one_year_ndvi_ratio_right\"] = ndvi[\"one_year_ndvi_adj_right\"] / ndvi[\"one_year_ndvi\"]\n",
    "\n",
    "ndvi[\"one_year_ndvi_adj_sum\"] = ndvi[\"one_year_ndvi\"] + ndvi[\"one_year_ndvi_adj_left\"] + ndvi[\"one_year_ndvi_adj_right\"] \n",
    "\n",
    "ndvi[\"one_year_ndvi_adj_mean\"] = ndvi[\"one_year_ndvi_adj_sum\"]/3 \n",
    "\n",
    "\n",
    "ndvi = ndvi[ndvi.index.isin(sm.index)]\n",
    "\n",
    "forecast_spi = forecast_spi[forecast_spi.index.isin(sm.index)]\n",
    "mixed_spi = mixed_spi[mixed_spi.index.isin(sm.index)]\n",
    "chirps_actual = chirps_actual[chirps_actual.index.isin(sm.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['aoi_id', \n",
    "              'month_ndvi_mean','one_year_ndvi','one_year_ndvi_adj_left',\n",
    "              'one_year_ndvi_adj_right','one_year_ndvi_diff_left','one_year_ndvi_diff_right',\n",
    "              'one_year_ndvi_ratio_left', 'one_year_ndvi_ratio_right','one_year_ndvi_adj_sum',\n",
    "              'one_year_ndvi_adj_mean',\n",
    "              'month_sm_mean', 'forecast_spi_1',\n",
    "       'forecast_spi_2', 'forecast_spi_3', 'forecast_spi_4', 'forecast_spi_5',\n",
    "       'forecast_spi_6','mixed_spi','chirps_actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = ndvi.join(sm, lsuffix=\"\", rsuffix=\"_r\")\n",
    "final_df = final_df.join(forecast_spi, lsuffix=\"\", rsuffix=\"_r\")\n",
    "final_df = final_df.join(mixed_spi, lsuffix=\"\", rsuffix=\"_r\")\n",
    "final_df = final_df.join(chirps_actual, lsuffix=\"\", rsuffix=\"_r\")[cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"chirps_actual\"] = final_df[\"chirps_actual\"].shift(1) # to use chirps from month before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    final_df[f\"chirps_actual_{i}m\"] = final_df[\"chirps_actual\"].shift(i)\n",
    "    final_df[f\"month_ndvi_mean_{i}m\"] = final_df[\"month_ndvi_mean\"].shift(i)\n",
    "    final_df[f\"month_sm_mean_{i}m\"] = final_df[\"month_sm_mean\"].shift(i)\n",
    "    final_df[f\"mixed_spi_{i}m\"] = final_df.mixed_spi.rolling(min_periods=1, window=i+1).sum()\n",
    "\n",
    "for i in range(1,7):\n",
    "   \n",
    "    if i == 1:        \n",
    "        final_df[f\"forecast_spi_{i}_cumsum_2\"] = final_df[f\"mixed_spi\"] + final_df[f\"forecast_spi_1\"] \n",
    "        final_df[f\"forecast_spi_{i}_cumsum_3\"] = final_df[f\"mixed_spi_1m\"] + final_df[f\"forecast_spi_1\"]\n",
    "    elif i == 2:\n",
    "        final_df[f\"forecast_spi_{i}_cumsum_2\"] = final_df[f\"forecast_spi_1\"] + final_df[f\"forecast_spi_2\"] \n",
    "        final_df[f\"forecast_spi_{i}_cumsum_3\"] = final_df[f\"mixed_spi\"] + final_df[f\"forecast_spi_{i}_cumsum_2\"]\n",
    "    else:\n",
    "        final_df[f\"forecast_spi_{i}_cumsum_2\"] = final_df[f\"forecast_spi_{i-1}\"] + final_df[f\"forecast_spi_{i}\"] \n",
    "        final_df[f\"forecast_spi_{i}_cumsum_3\"] = final_df[f\"forecast_spi_{i-2}\"] + final_df[f\"forecast_spi_{i}_cumsum_2\"] \n",
    "        \n",
    "#final_df[\"month_ndvi_mean_cumsum_2\"] = final_df.month_ndvi_mean.rolling(min_periods=1, window=2).sum()\n",
    "#final_df[\"month_ndvi_mean_cumsum_3\"] = final_df.month_ndvi_mean.rolling(min_periods=1, window=3).sum()\n",
    "\n",
    "#final_df[\"month_sm_mean_cumsum_2\"] = final_df.month_sm_mean.rolling(min_periods=1, window=2).sum()\n",
    "#final_df[\"month_sm_mean_cumsum_3\"] = final_df.month_sm_mean.rolling(min_periods=1, window=3).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,8):\n",
    "    final_df[f\"target_ndvi_{i}\"] = final_df.month_ndvi_mean.shift(-i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7633b",
   "metadata": {},
   "source": [
    "# One Month model\n",
    "\n",
    "- Train each model separetely to get the most out of the dataset. If I filter everything many points dissapear because of NaN\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "target_cols = ['target_ndvi_1','target_ndvi_2',\n",
    "               'target_ndvi_3','target_ndvi_4',\n",
    "               'target_ndvi_5', 'target_ndvi_6', 'target_ndvi_7']\n",
    "\n",
    "forecast_spi_cols = ['forecast_spi_1', 'forecast_spi_2', 'forecast_spi_3', \n",
    "                     'forecast_spi_4', 'forecast_spi_5','forecast_spi_6',\n",
    "                     'forecast_spi_1_cumsum_2',\n",
    "                     'forecast_spi_1_cumsum_3',\n",
    "                     'forecast_spi_2_cumsum_2',\n",
    "                     'forecast_spi_2_cumsum_3',\n",
    "                     'forecast_spi_3_cumsum_2',\n",
    "                     'forecast_spi_3_cumsum_3',\n",
    "                     'forecast_spi_4_cumsum_2',\n",
    "                     'forecast_spi_4_cumsum_3',\n",
    "                     'forecast_spi_5_cumsum_2',\n",
    "                     'forecast_spi_5_cumsum_3',\n",
    "                     'forecast_spi_6_cumsum_2',\n",
    "                     'forecast_spi_6_cumsum_3',\n",
    "                     ]\n",
    "             \n",
    "wfp_cols = forecast_spi_cols + ['mixed_spi',\n",
    "                                'chirps_actual','chirps_actual_1m', 'chirps_actual_2m']\n",
    "            \n",
    "oxeo_cols_ndvi = wfp_cols + ['month_ndvi_mean', 'month_ndvi_mean_1m','month_ndvi_mean_2m',\n",
    "'month_ndvi_mean_3m','month_ndvi_mean_4m','one_year_ndvi','one_year_ndvi_adj_left',\n",
    "              'one_year_ndvi_adj_right','one_year_ndvi_diff_left','one_year_ndvi_diff_right',\n",
    "              'one_year_ndvi_ratio_left', 'one_year_ndvi_ratio_right','one_year_ndvi_adj_sum',\n",
    "              'one_year_ndvi_adj_mean']\n",
    "oxeo_cols_sm = oxeo_cols_ndvi + ['month_sm_mean', 'month_sm_mean_1m', 'month_sm_mean_2m',\n",
    "                                    'month_sm_mean_3m', 'month_sm_mean_4m']\n",
    "                        \n",
    "                    \n",
    "            \n",
    "all_cols = {\n",
    "    \"wfp\":wfp_cols,\n",
    "    \"oxeo_ndvi\": oxeo_cols_ndvi,\n",
    "    \"oxeo_sm\": oxeo_cols_sm,\n",
    "    \"target\": target_cols,\n",
    "    \"all\":oxeo_cols_sm+target_cols,\n",
    "    \"all_no_target\":oxeo_cols_sm,\n",
    "    \"spi\": forecast_spi_cols,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import boruta_py\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = final_df[all_cols['all']].dropna()\n",
    "X_train = model_df[all_cols['all_no_target']][:-10]\n",
    "X_test = model_df[all_cols['all_no_target']][-10:]\n",
    "\n",
    "y_train = model_df[all_cols[\"target\"]][:-10]\n",
    "y_test = model_df[all_cols[\"target\"]][-10:]\n",
    "\n",
    "X_train_wfp = X_train[all_cols[\"wfp\"]]\n",
    "X_train_oxeo_ndvi = X_train[all_cols[\"oxeo_ndvi\"]]\n",
    "X_train_oxeo_sm = X_train[all_cols[\"oxeo_sm\"]]\n",
    "\n",
    "\n",
    "X_test_wfp = X_test[all_cols[\"wfp\"]]\n",
    "X_test_oxeo_ndvi = X_test[all_cols[\"oxeo_ndvi\"]]\n",
    "X_test_oxeo_sm = X_test[all_cols[\"oxeo_sm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9dc737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_train_wfp.shape,X_train_oxeo_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train,y_train, grid_search_params,\n",
    "                 cv_scoring= {'r2': 'r2','neg_mse': 'neg_mean_squared_error'},\n",
    "                 boruta=True):\n",
    "                 \n",
    "    cols_to_use = [x for x in X_train.columns if x not in all_cols['spi']]  \n",
    "    \n",
    "    valid_forecasts = {\n",
    "        i: [f'forecast_spi_{i}', f'forecast_spi_{i}_cumsum_2',f'forecast_spi_{i}_cumsum_3'] for i in range(1,7)\n",
    "    }\n",
    "    \n",
    "    #valid_forecasts = {\n",
    "    #    i: [f'forecast_spi_{i}'] for i in range(1,7)\n",
    "    #}\n",
    "    \n",
    "    \n",
    "    #features = X_train.columns\n",
    "\n",
    "    best_params = {}\n",
    "    best_models = {}\n",
    "    cv_scores = {}\n",
    "    boruta_features = {}\n",
    "    for i in range(7):\n",
    "        features = cols_to_use \n",
    "        for j in range(1,i+1):\n",
    "            features = features + valid_forecasts[j]\n",
    "        \n",
    "        target_col = f\"target_ndvi_{i+1}\"\n",
    "\n",
    "        if boruta:\n",
    "            forest = xgb.XGBRegressor(n_jobs=-1)\n",
    "            # define Boruta feature selection method\n",
    "\n",
    "            feat_selector = boruta_py.BorutaPy(forest, verbose=0, perc=90, n_estimators=50)\n",
    "            # find all relevant features\n",
    "            feat_selector.fit(X_train[features].values, y_train[target_col].values)\n",
    "            Z = [x for r,x in sorted(zip(feat_selector.ranking_,X_train[features].columns)) if r ==1]\n",
    "            selected_features = Z\n",
    "        else:\n",
    "            selected_features = features\n",
    "        print(\"Features to be use: \", selected_features)\n",
    "        #print(\"Boruta selected: \", selected_features)\n",
    "\n",
    "        xg_reg = xgb.XGBRegressor(n_jobs=-1)\n",
    "\n",
    "        params = grid_search_params\n",
    "        \n",
    "        cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "        xgb_grid = GridSearchCV(xg_reg,\n",
    "                                params,\n",
    "                                cv = cv, scoring=\"r2\",\n",
    "                                n_jobs = -1,\n",
    "                                verbose=True)\n",
    "\n",
    "        xgb_grid.fit(X_train[selected_features],y_train[target_col])\n",
    "        best_params[i] = xgb_grid.best_params_\n",
    "        best_models[i] = xgb_grid.best_estimator_\n",
    "        \n",
    "        cv_scores[i] = cross_validate(xgb_grid.best_estimator_,X_train[selected_features],\n",
    "                     y_train[target_col],cv=cv, scoring=cv_scoring)\n",
    "                     \n",
    "        boruta_features[i] = selected_features\n",
    "\n",
    "    return best_models, best_params, cv_scores, boruta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74238d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_final_and_eval(cv_train_results):\n",
    "    models = []\n",
    "    _, model_params, _, boruta_features = cv_train_results\n",
    "    for i in range(7):\n",
    "        xgb_reg = xgb.XGBRegressor(**model_params[i])\n",
    "        xgb_reg.fit(X_train[boruta_features[i]], y_train[target_cols[i]])\n",
    "        models.append(xgb_reg)\n",
    "\n",
    "    preds = []\n",
    "    y_true = []\n",
    "    for i in range(7):\n",
    "        preds.append(models[i].predict(X_test[boruta_features[i]]))\n",
    "        y_true.append(y_test[target_cols[i]])\n",
    "\n",
    "    for i in range(7):\n",
    "        y_true[i].plot(label=\"y_true\", legend=True)\n",
    "        pd.Series(preds[i],index=y_true[i].index).plot(label=\"y_true\", legend=True)\n",
    "        plt.show()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp = {'objective':['reg:squarederror'],\n",
    "              'max_depth': [2,3],\n",
    "              'n_estimators': [50]}\n",
    "train_wfp_results = train_models(X_train_wfp,y_train,gsp, boruta=False)\n",
    "train_ndvi_results = train_models(X_train_oxeo_ndvi,y_train,gsp, boruta=True)\n",
    "train_sm_results = train_models(X_train_oxeo_sm,y_train,gsp, boruta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfp_models, wfp_params, wfp_scores, _ = train_wfp_results\n",
    "mean_scores_wfp = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in wfp_scores[i].items():\n",
    "        mean_scores_wfp[i][key] = value.mean()\n",
    "\n",
    "oxeo_models, oxeo_params, oxeo_scores, _ = train_ndvi_results\n",
    "\n",
    "mean_scores_ndvi = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in oxeo_scores[i].items():\n",
    "        mean_scores_ndvi[i][key] = value.mean() \n",
    "\n",
    "_, _, sm_scores, _ = train_sm_results\n",
    "mean_scores_sm = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in sm_scores[i].items():\n",
    "        mean_scores_sm[i][key] = value.mean()\n",
    "\n",
    "\n",
    "(-pd.DataFrame(mean_scores_wfp).loc[\"test_neg_mse\"]).plot(label=\"wfp\", legend=True)\n",
    "(-pd.DataFrame(mean_scores_ndvi).loc[\"test_neg_mse\"]).plot(label=\"ndvi\", legend=True)\n",
    "(-pd.DataFrame(mean_scores_sm).loc[\"test_neg_mse\"]).plot(label=\"sm\", legend=True)\n",
    "\n",
    "plt.ylim([0.0005, 0.006])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfp_models, wfp_params, wfp_scores, _ = train_wfp_results\n",
    "mean_scores_wfp = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in wfp_scores[i].items():\n",
    "        mean_scores_wfp[i][key] = value.mean()\n",
    "\n",
    "oxeo_models, oxeo_params, oxeo_scores, _ = train_ndvi_results\n",
    "\n",
    "mean_scores_ndvi = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in oxeo_scores[i].items():\n",
    "        mean_scores_ndvi[i][key] = value.mean() \n",
    "\n",
    "_, _, sm_scores, _ = train_sm_results\n",
    "mean_scores_sm = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in sm_scores[i].items():\n",
    "        mean_scores_sm[i][key] = value.mean()\n",
    "\n",
    "\n",
    "(-pd.DataFrame(mean_scores_wfp).loc[\"test_neg_mse\"]).plot(label=\"wfp\", legend=True)\n",
    "(-pd.DataFrame(mean_scores_ndvi).loc[\"test_neg_mse\"]).plot(label=\"ndvi\", legend=True)\n",
    "(-pd.DataFrame(mean_scores_sm).loc[\"test_neg_mse\"]).plot(label=\"sm\", legend=True)\n",
    "\n",
    "plt.ylim([0.0005, 0.006])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfp_models, wfp_params, wfp_scores, _ = train_wfp_results\n",
    "mean_scores_wfp = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in wfp_scores[i].items():\n",
    "        mean_scores_wfp[i][key] = value.mean()\n",
    "\n",
    "oxeo_models, oxeo_params, oxeo_scores, _ = train_ndvi_results\n",
    "\n",
    "mean_scores_ndvi = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in oxeo_scores[i].items():\n",
    "        mean_scores_ndvi[i][key] = value.mean() \n",
    "\n",
    "_, _, sm_scores, _ = train_sm_results\n",
    "mean_scores_sm = defaultdict(dict)\n",
    "for i in range(7):\n",
    "    for key, value in sm_scores[i].items():\n",
    "        mean_scores_sm[i][key] = value.mean()\n",
    "\n",
    "\n",
    "(-pd.DataFrame(mean_scores_wfp).loc[\"test_neg_mse\"]).plot(label=\"wfp\", legend=True)\n",
    "(-pd.DataFrame(mean_scores_ndvi).loc[\"test_neg_mse\"]).plot(label=\"ndvi\", legend=True)\n",
    "(-pd.DataFrame(mean_scores_sm).loc[\"test_neg_mse\"]).plot(label=\"sm\", legend=True)\n",
    "\n",
    "plt.ylim([0.0005, 0.006])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_and_eval(train_sm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5db050",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a8527",
   "metadata": {},
   "source": [
    "# Model training with moisture\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "models = []\n",
    "extra_cols = [\"month_sm_mean\"]\n",
    "test_size = 20 # percentage\n",
    "for i in tqdm(range(7)):\n",
    "\n",
    "    if i == 0:\n",
    "        cols_to_use = ['month_ndvi_mean','mixed_spi_cumsum_3']\n",
    "    else:\n",
    "        cols_to_use = ['month_ndvi_mean', \n",
    "                     f'forecast_spi_{i}_cumsum_3']\n",
    "    cols_to_use+=extra_cols\n",
    "    print(f\"Using features: {cols_to_use}\")\n",
    "    target_col = f\"target_ndvi_{i+1}\"\n",
    "    sm_df = final_df.dropna(subset=\"month_sm_mean\")\n",
    "    model_df = sm_df[cols_to_use + [target_col]].dropna()\n",
    "    model_df = model_df[2:] # to remove repeated cumsums\n",
    "    train = model_df[:-test_size]\n",
    "    test = model_df[-test_size:]\n",
    "    \n",
    "    y_train = train[[target_col]]\n",
    "    y_test = test[[target_col]]\n",
    "\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "    params = {'objective':['reg:squarederror'],\n",
    "              'learning_rate': [0.1,0.3,0.5], #so called `eta` value\n",
    "              'max_depth': [2, 4, 6,8,10,12],\n",
    "              'n_estimators': [50,100]}\n",
    "\n",
    "\n",
    "    xgb_grid = GridSearchCV(xg_reg,\n",
    "                            params,\n",
    "                            cv = TimeSeriesSplit(n_splits=3),\n",
    "                            n_jobs = -1,\n",
    "                            verbose=True)\n",
    "\n",
    "    xgb_grid.fit(train[cols_to_use],\n",
    "             y_train)\n",
    "    print(xgb_grid.best_params_)\n",
    "    #xg_reg.fit(X_train.values,y_train)\n",
    "    models.append(xgb_grid.best_estimator_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207971e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "preds = {}\n",
    "y_true = {}\n",
    "\n",
    "r2_scores = []\n",
    "for i in range(7):\n",
    "    if i == 0:\n",
    "        cols_to_use = ['month_ndvi_mean','mixed_spi_cumsum_3']\n",
    "    else:\n",
    "        cols_to_use = ['month_ndvi_mean', \n",
    "                     f'forecast_spi_{i}_cumsum_3']\n",
    "        \n",
    "    cols_to_use+=extra_cols\n",
    "    target_col = f\"target_ndvi_{i+1}\"\n",
    "    sm_df = final_df.dropna(subset=\"month_sm_mean\")\n",
    "    model_df = sm_df[cols_to_use + [target_col]].dropna()\n",
    "    \n",
    "    train = model_df[:-test_size]\n",
    "    test = model_df[-test_size:]\n",
    "    preds[i] = models[i].predict(test[cols_to_use])\n",
    "    y_true[i] = test[[f\"target_ndvi_{i+1}\"]].values[:,0]\n",
    "    \n",
    "    r2_scores.append(mean_squared_error(y_true[i], preds[i]))\n",
    "\n",
    "    sns.lineplot(data=pd.DataFrame({\"y_true\":y_true[i],\"y_pred\":preds[i]}))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fe49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869edf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231d6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10), sharey=True)\n",
    "for j in range(0,10):\n",
    "    sm_df = final_df.dropna(subset=\"month_sm_mean\")\n",
    "    instance = sm_df.dropna().iloc[-10+j]\n",
    "    instances_preds = []\n",
    "    for i in range(7):\n",
    "        if i == 0:\n",
    "            cols_to_use = ['month_ndvi_mean', 'mixed_spi', 'mixed_spi_cumsum_2', 'mixed_spi_cumsum_3']\n",
    "        else:\n",
    "            cols_to_use = ['month_ndvi_mean', \n",
    "                        f'forecast_spi_{i}', f'forecast_spi_{i}_cumsum_2', f'forecast_spi_{i}_cumsum_3']\n",
    "\n",
    "        cols_to_use+=extra_cols\n",
    "        instances_preds.append(models[i].predict(instance[cols_to_use].values.reshape(1,-1))[0])\n",
    "    axs[(j//5),j%5].plot(instance.values[-7:],label=f\"y_true {str(instance.name)}\")\n",
    "    axs[(j//5),j%5].plot(instances_preds, label=\"y_pred\")\n",
    "    axs[(j//5),j%5].legend()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165d81e",
   "metadata": {},
   "source": [
    "# Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "baseline_models = []\n",
    "\n",
    "test_size = 20 # percentage\n",
    "for i in tqdm(range(7)):\n",
    "\n",
    "    if i == 0:\n",
    "        cols_to_use = ['month_ndvi_mean', 'mixed_spi', 'mixed_spi_cumsum_2', 'mixed_spi_cumsum_3']\n",
    "    else:\n",
    "        cols_to_use = ['month_ndvi_mean', \n",
    "                    f'forecast_spi_{i}', f'forecast_spi_{i}_cumsum_2', f'forecast_spi_{i}_cumsum_3']\n",
    "\n",
    "    print(f\"Using features: {cols_to_use}\")\n",
    "    target_col = f\"target_ndvi_{i+1}\"\n",
    "    sm_df = final_df.dropna(subset=\"month_sm_mean\")\n",
    "    model_df = sm_df[cols_to_use + [target_col]].dropna()\n",
    "    model_df = model_df[2:] # to remove repeated cumsums\n",
    "    train = model_df[:-test_size]\n",
    "    test = model_df[-test_size:]\n",
    "    \n",
    "    y_train = train[[target_col]]\n",
    "    y_test = test[[target_col]]\n",
    "\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "    params = {'objective':['reg:squarederror'],\n",
    "              'learning_rate': [0.1,0.3,0.5], #so called `eta` value\n",
    "              'max_depth': [4, 6,8,10,12],\n",
    "              'n_estimators': [100,200,1000]}\n",
    "\n",
    "\n",
    "    xgb_grid = GridSearchCV(xg_reg,\n",
    "                            params,\n",
    "                            cv = TimeSeriesSplit(n_splits=3),\n",
    "                            n_jobs = -1,\n",
    "                            verbose=True)\n",
    "\n",
    "    xgb_grid.fit(train[cols_to_use],\n",
    "             y_train)\n",
    "    print(xgb_grid.best_params_)\n",
    "    #xg_reg.fit(X_train.values,y_train)\n",
    "    baseline_models.append(xgb_grid.best_estimator_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "preds = {}\n",
    "y_true = {}\n",
    "\n",
    "baseline_r2_scores = []\n",
    "for i in range(7):\n",
    "    if i == 0:\n",
    "        cols_to_use = ['month_ndvi_mean', 'mixed_spi', 'mixed_spi_cumsum_2', 'mixed_spi_cumsum_3']\n",
    "    else:\n",
    "        cols_to_use = ['month_ndvi_mean', \n",
    "                    f'forecast_spi_{i}', f'forecast_spi_{i}_cumsum_2', f'forecast_spi_{i}_cumsum_3']\n",
    "    target_col = f\"target_ndvi_{i+1}\"\n",
    "    sm_df = final_df.dropna(subset=\"month_sm_mean\")\n",
    "    model_df = sm_df[cols_to_use + [target_col]].dropna()\n",
    "    \n",
    "    train = model_df[:-test_size]\n",
    "    test = model_df[-test_size:]\n",
    "    preds[i] = baseline_models[i].predict(test[cols_to_use])\n",
    "    y_true[i] = test[[f\"target_ndvi_{i+1}\"]].values[:,0]\n",
    "    \n",
    "    baseline_r2_scores.append(mean_squared_error(y_true[i], preds[i]))\n",
    "\n",
    "    sns.lineplot(data=pd.DataFrame({\"y_true\":y_true[i],\"y_pred\":preds[i]}))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b969d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(instance.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10), sharey=True)\n",
    "for j in range(0,10):\n",
    "    sm_df = final_df.dropna(subset=\"month_sm_mean\")\n",
    "    instance = sm_df.dropna().iloc[-10+j]\n",
    "    instances_preds = []\n",
    "    for i in range(7):\n",
    "        if i == 0:\n",
    "            cols_to_use = ['month_ndvi_mean', 'mixed_spi', 'mixed_spi_cumsum_2', 'mixed_spi_cumsum_3']\n",
    "        else:\n",
    "            cols_to_use = ['month_ndvi_mean', \n",
    "                        f'forecast_spi_{i}', f'forecast_spi_{i}_cumsum_2', f'forecast_spi_{i}_cumsum_3']\n",
    "        instances_preds.append(baseline_models[i].predict(instance[cols_to_use].values.reshape(1,-1))[0])\n",
    "    axs[(j//5),j%5].plot(instance.values[-7:],label=f\"y_true {str(instance.name)}\")\n",
    "    axs[(j//5),j%5].plot(instances_preds, label=\"y_pred\")\n",
    "    axs[(j//5),j%5].legend()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"sm\":r2_scores, \"baseline\": baseline_r2_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61305983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
