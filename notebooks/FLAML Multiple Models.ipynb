{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869418c2-1a03-4808-82b3-b977defc87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "import httpx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from shapely import geometry\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a833948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def get_keyed_values(results, label, keyed_value, new_col):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.labels = df.labels.map(lambda x: x[0])\n",
    "    df = df[df.labels == label]\n",
    "    df[new_col] = df.keyed_values.apply(lambda x: x.get(keyed_value))\n",
    "    df = df.drop_duplicates(subset=[\"aoi_id\", \"datetime\"]).dropna()\n",
    "    df.datetime = pd.to_datetime(df.datetime)\n",
    "    \n",
    "    \n",
    "    if keyed_value == \"FORECAST_SPI\":\n",
    "        months_df = df[new_col].apply(pd.Series)\n",
    "        months_df.columns = [f\"{new_col}_1\", f\"{new_col}_2\",\n",
    "                             f\"{new_col}_3\", f\"{new_col}_4\",\n",
    "                             f\"{new_col}_5\", f\"{new_col}_6\"]\n",
    "        df = pd.concat([df.drop([new_col], axis=1), months_df], axis=1)\n",
    "    \n",
    "        df.index = df[\"datetime\"]\n",
    "        \n",
    "    elif keyed_value == \"mean_value\" or keyed_value == \"N_PIXELS\":\n",
    "        df = df.groupby([\"datetime\"]).mean().resample(\"MS\").mean()\n",
    "        #df.index = df.index.map(lambda x: x.replace(day=1))\n",
    "      \n",
    "    else:\n",
    "        df.index = df[\"datetime\"]\n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209645c1",
   "metadata": {},
   "source": [
    "2179, 2416, 2199, 2359, 2411, 2453, 2459, 2462, 2213, 2182, 2233, 2185, 2181, 2187, 2384, 2219, 2269, 2270, 2221, 2275, 2344, 2150, 2137, 2168, 2358, 2411, 2413, 2415, 2207, 2370\n",
    "\n",
    "\n",
    "2179, 2411, 2453, 2182, 2185, 2181, 2187, 2384, 2344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21562853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tete_aga = [2179, 2416, 2199, 2359, 2411, 2453, 2459, 2462, 2213, 2182, 2233, 2185, 2181, 2187, 2384, 2219, 2269, 2270, 2221, 2275, 2344, 2150, 2137, 2168, 2358, 2411, 2413, 2415, 2207, 2370]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b910999-3ab4-4edc-9d5a-8c24601e38eb",
   "metadata": {},
   "source": [
    "# API Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac181a62-5d07-46b6-bd8d-f56419f7ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://localhost:8081/\"\n",
    "client = httpx.Client(base_url=base_url)\n",
    "r = client.post(\n",
    "    \"auth/token\",\n",
    "    data={\"username\": \"fran.dorr@gmail.com\", \"password\": \"fran123\"},\n",
    ")\n",
    "token = json.loads(r.text)[\"access_token\"]\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3989414-2d25-4d8b-aa9f-07426b36bf91",
   "metadata": {},
   "source": [
    "# Get agricultural areas geoms from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298df819-d44f-4b43-a7f2-b9c67c003113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = client.get(\"aoi/\", params=dict(id=tete_aga), headers=headers)\n",
    "res = json.loads(r.text)\n",
    "polygons = geometry.shape(res[\"features\"][0][\"geometry\"])\n",
    "# get the bbox for all the ag areas\n",
    "box = polygons.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5293bd6-f5d3-4758-8735-7e80074335d0",
   "metadata": {},
   "source": [
    "# Get Events from DB \n",
    "- Date range from 2019 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7722d23-d787-42b5-b9fa-34260117ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = \"1985-01-02\"\n",
    "end_datetime = \"2022-08-31\"\n",
    "\n",
    "ndvi_cols = [\"month_ndvi_mean\"]\n",
    "sm_cols = [\"month_sm_mean\"]\n",
    "chirps_cols = [\"chirps_actual\"]\n",
    "forecast_spi_cols = [\"mixed_spi\",\n",
    "                     \"forecast_spi_1\", \n",
    "                     \"forecast_spi_2\",\n",
    "                     \"forecast_spi_3\",\n",
    "                     \"forecast_spi_4\",\n",
    "                     \"forecast_spi_5\",\n",
    "                     \"forecast_spi_6\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65544d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season_features(df,season,feature,model_forecast):\n",
    "    df[f\"past_{season}_{feature}\"] = sm[f\"month_{feature}_mean\"].shift(season+model_forecast).interpolate() \n",
    "    df[f\"past_{season}_{feature}_adj_left\"] = df[f\"month_{feature}_mean\"].shift(season+1+model_forecast).interpolate() \n",
    "    df[f\"past_{season}_{feature}_adj_right\"] =  df[f\"month_{feature}_mean\"].shift(season-1+model_forecast).interpolate() \n",
    "\n",
    "    df[f\"past_{season}_{feature}_diff_left\"] =  df[f\"past_{season}_{feature}\"] \n",
    "    df[f\"past_{season}_{feature}_diff_right\"] = df[f\"past_{season}_{feature}\"] \n",
    "\n",
    "    df[f\"past_{season}_{feature}_ratio_left\"] = df[f\"past_{season}_{feature}_adj_left\"] /  df[f\"past_{season}_{feature}\"]\n",
    "    df[f\"past_{season}_{feature}_ratio_right\"] =  df[f\"past_{season}_{feature}_adj_right\"] /  df[f\"past_{season}_{feature}\"]\n",
    "\n",
    "    df[f\"past_{season}_{feature}_adj_sum\"] =  df[f\"past_{season}_{feature}\"] +  df[f\"past_{season}_{feature}_adj_left\"] + df[f\"past_{season}_{feature}_adj_right\"] \n",
    "\n",
    "    df[f\"past_{season}_{feature}_adj_mean\"] = df[f\"past_{season}_{feature}_adj_sum\"]/3 \n",
    "    \n",
    "    new_cols = [f'past_{season}_{feature}',f'past_{season}_{feature}_adj_left',\n",
    "                f'past_{season}_{feature}_adj_right',\n",
    "                f'past_{season}_{feature}_diff_left',\n",
    "                f'past_{season}_{feature}_diff_right',\n",
    "                f'past_{season}_{feature}_ratio_left', \n",
    "                f'past_{season}_{feature}_ratio_right',\n",
    "                f'past_{season}_{feature}_adj_sum',\n",
    "                f'past_{season}_{feature}_adj_mean']\n",
    "    return df, new_cols\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(start_datetime, end_datetime, ag_areas, model_forecast = 1, season=7):\n",
    "    all_df = pd.DataFrame()\n",
    "    failed = []\n",
    "    new_sm_cols = sm_cols\n",
    "    cols_to_use = sm_cols + chirps_cols + [forecast_spi_cols[model_forecast-1]] #+ we_cols#+ ndvi_cols\n",
    "\n",
    "    for ag_area in ag_areas:\n",
    "\n",
    "        try:\n",
    "            r = client.get(\n",
    "                    \"events/\",\n",
    "                    params=dict(\n",
    "                        aoi_id=ag_area,\n",
    "                        start_datetime=start_datetime,\n",
    "                        end_datetime=end_datetime,\n",
    "                        limit=10000,\n",
    "                    ),\n",
    "                    headers=headers,\n",
    "                    timeout=60,\n",
    "                )\n",
    "            aga_results = json.loads(r.text)[\"events\"]\n",
    "\n",
    "            ndvi = get_keyed_values(aga_results, \"ndvi\", \"mean_value\", \"month_ndvi_mean\")\n",
    "            sm = get_keyed_values(aga_results, \"soil_moisture\", \"mean_value\", \"month_sm_mean\")\n",
    "            chirps_actual = get_keyed_values(aga_results, \"total_precipitation\", \"CHIRPS_SPI_actual\", \"chirps_actual\")\n",
    "            forecast_spi = get_keyed_values(aga_results, \"total_precipitation\", \"FORECAST_SPI\", \"forecast_spi\")\n",
    "            mixed_spi = get_keyed_values(aga_results, \"total_precipitation\", \"MIXED_SPI\", \"mixed_spi\")\n",
    "        \n",
    "            if season:\n",
    "                sm, new_sm_cols = add_season_features(sm, season, \"sm\", model_forecast)\n",
    "                new_sm_cols = list(set(sm_cols + new_sm_cols))\n",
    "                cols_to_use = list(set(cols_to_use + new_sm_cols))        \n",
    "\n",
    "            final_df = ndvi.join(sm, lsuffix=\"\", rsuffix=\"_r\")\n",
    "            final_df = final_df.join(forecast_spi, lsuffix=\"\", rsuffix=\"_r\")\n",
    "            final_df = final_df.join(mixed_spi, lsuffix=\"\", rsuffix=\"_r\")\n",
    "            final_df = final_df.join(chirps_actual, lsuffix=\"\", rsuffix=\"_r\")\n",
    "            final_df[\"chirps_actual\"] = final_df.chirps_actual.shift(1)\n",
    "            final_df[f\"target_ndvi\"] = final_df.month_ndvi_mean.shift(-model_forecast)\n",
    "\n",
    "            import numpy as np\n",
    "\n",
    "            final_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            final_df = final_df.drop(columns=[\"month_ndvi_mean\"]).dropna(subset=cols_to_use+[\"target_ndvi\"])\n",
    "            #final_df = final_df.dropna()\n",
    "            print(final_df.shape)\n",
    "\n",
    "            all_df = pd.concat([all_df, final_df], axis=0)\n",
    "        except Exception as e:\n",
    "            print(ag_area, f\" failed with exception {e}.\")\n",
    "            failed.append(ag_area)\n",
    "    all_df = all_df.sort_index()\n",
    "    all_df = all_df[cols_to_use + [\"aoi_id\", \"target_ndvi\"]]\n",
    "    return all_df, [new_sm_cols, chirps_cols,[forecast_spi_cols[model_forecast-1]] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087119f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function modified from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.options.display.max_columns = 30\n",
    "import os\n",
    "import re\n",
    "from colorama import Fore, Back, Style\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.style.use('fivethirtyeight')\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def plot_cv_indices(cv, n_splits, X, y, date_col = None):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = (11, 7))\n",
    "    \n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=10, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits))\n",
    "    \n",
    "    if date_col is not None:\n",
    "        tick_locations  = ax.get_xticks()\n",
    "        tick_dates = [\" \"] + date_col.iloc[list(tick_locations[1:-1])].astype(str).tolist() + [\" \"]\n",
    "\n",
    "        tick_locations_str = [str(int(i)) for i in tick_locations]\n",
    "        new_labels = ['\\n\\n'.join(x) for x in zip(list(tick_locations_str), tick_dates) ]\n",
    "        ax.set_xticks(tick_locations)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "    \n",
    "    ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "              ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4236b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def train_flaml(subset, X_train, y_train, X_test, y_test, budget):\n",
    "    cols_to_use = list(chain.from_iterable(subset))\n",
    "    \n",
    "    selected_features = cols_to_use\n",
    "    \n",
    "    \n",
    "    automl = AutoML(time_budget=budget, seed=42, \n",
    "                    estimator_list=[\"lgbm\", \"xgboost\"], starting_points = \"data\",\n",
    "                    task=\"regression\", verbose=0, n_jobs=-1, metric=\"mse\", limit_train_time=3)\n",
    "    \n",
    "    \n",
    "    automl.fit(X_train[selected_features], y_train, X_val=X_test, y_val=y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    preds = automl.predict(X_test[selected_features])\n",
    "    y_true = y_test\n",
    "\n",
    "    return {\"model\": automl.best_estimator, \n",
    "            \"cols\": selected_features, \n",
    "            \"mse\": mean_squared_error(y_true,preds),\n",
    "            \"y_true\": y_true,\n",
    "            \"y_pred\": preds,\n",
    "            \"aoi_id\": X_test[\"aoi_id\"]\n",
    "            }\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf13b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "from flaml import AutoML\n",
    "from itertools import chain, combinations\n",
    "from operator import add\n",
    "\n",
    "def all_subsets(ss):\n",
    "    return chain(*map(lambda x: combinations(ss, x), range(0, len(ss)+1)))\n",
    "    \n",
    "all_res = []\n",
    "for model_forecast in range(1,8):\n",
    "    print(f\"RUNNING MODEL {model_forecast}\")\n",
    "    all_df, cols_to_use = extract_features(start_datetime, end_datetime, tete_aga, model_forecast = model_forecast)\n",
    "    \n",
    "    X = all_df.drop([\"target_ndvi\"],axis=1)\n",
    "    y = all_df[\"target_ndvi\"]\n",
    "    \n",
    "    \n",
    "    n_splits = 5\n",
    "    tscv = TimeSeriesSplit(n_splits,test_size=int(X.shape[0]*0.15))\n",
    "    \n",
    "    all_cols = cols_to_use#[sm_cols , chirps_cols , forecast_spi_cols[:model_forecast] ]#, we_cols, ndvi_cols]\n",
    "\n",
    "    res = []\n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        # check there is no day overlap between train and test\n",
    "        train_dates = X.iloc[train_index].index\n",
    "        test_dates = X.iloc[test_index].index\n",
    "        to_delete = []\n",
    "        for i,ti in enumerate(test_index):\n",
    "            if X.iloc[ti].name in train_dates:\n",
    "                to_delete.append(i)\n",
    "        test_index = np.delete(test_index, to_delete)\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        for subset in list(all_subsets(all_cols))[1:]:\n",
    "            res.append(train_flaml(subset, X_train, y_train, X_test, y_test, budget=3))\n",
    "            \n",
    "    final_res = pd.DataFrame(res)\n",
    "    final_res[\"cols\"] = final_res.cols.apply(tuple)\n",
    "    best_df = final_res[final_res.cols==final_res.groupby(\"cols\").mean().sort_values(by=\"mse\").iloc[0].name]\n",
    "    base_df = final_res[final_res.cols==(\"chirps_actual\", forecast_spi_cols[model_forecast-1])]\n",
    "    all_res.append(final_res.groupby(\"cols\").mean().sort_values(by=\"mse\"))\n",
    "\n",
    "    cv_mse = pd.DataFrame()\n",
    "    for row in best_df.iterrows():\n",
    "        aoi_ids = row[1][\"aoi_id\"]\n",
    "        y_true = row[1][\"y_true\"]\n",
    "        y_pred = row[1][\"y_pred\"]\n",
    "        df_cv = pd.DataFrame({\"aoi_id\":aoi_ids, \"y_true\":y_true, \"y_pred\":y_pred})\n",
    "        cv_mse=pd.concat([cv_mse, df_cv.groupby(\"aoi_id\").agg(lambda x: mean_squared_error(**x))], axis=0)\n",
    "    best_by_aoi = cv_mse.groupby(\"aoi_id\").mean()[\"y_true\"].copy()\n",
    "\n",
    "    for row in base_df.iterrows():\n",
    "        aoi_ids = row[1][\"aoi_id\"]\n",
    "        y_true = row[1][\"y_true\"]\n",
    "        y_pred = row[1][\"y_pred\"]\n",
    "        df_cv = pd.DataFrame({\"aoi_id\":aoi_ids, \"y_true\":y_true, \"y_pred\":y_pred})\n",
    "        cv_mse=pd.concat([cv_mse, df_cv.groupby(\"aoi_id\").agg(lambda x: mean_squared_error(**x))], axis=0)\n",
    "    base_by_aoi = cv_mse.groupby(\"aoi_id\").mean()[\"y_true\"].copy()\n",
    "\n",
    "    final_by_aoi = pd.concat([best_by_aoi, base_by_aoi], axis=1)\n",
    "    final_by_aoi.columns = [\"mse_sm\", \"mse_spi\"]\n",
    "    final_by_aoi.to_csv(f'cv_mse_by_aoi_{model_forecast}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
