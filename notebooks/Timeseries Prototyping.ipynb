{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8291530",
   "metadata": {},
   "source": [
    "# Timeseries and met data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869418c2-1a03-4808-82b3-b977defc87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import altair as alt\n",
    "import httpx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from shapely import geometry\n",
    "from shapely.ops import unary_union\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# This is a stationary test for timeseries\n",
    "def adf_test(timeseries):\n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21562853",
   "metadata": {},
   "outputs": [],
   "source": [
    "tete_wb = [\"1953\", \"1954\", \"1955\", \"1956\", \"1975\", \"1966\", \"1967\", \"1968\", \"1981\", \"1969\", \"1970\", \"1971\", \"1972\", \"1973\", \"1974\", \"1988\"]\n",
    "tete_aga = [\"2363\", \"2189\", \"2190\", \"2191\", \"2202\", \"2192\", \"2193\", \"2194\", \"2203\", \"2195\", \"2196\", \"2197\", \"2198\", \"2199\", \"2200\", \"2201\", \"2204\", \"2205\", \"2206\", \"2208\", \"2209\", \"2207\", \"2210\", \"2211\", \"2212\", \"2213\", \"2214\", \"2215\", \"2216\", \"2359\", \"2360\", \"2361\", \"2362\", \"2364\", \"2365\", \"2366\", \"2367\", \"2368\", \"2369\", \"2370\", \"2371\", \"2372\", \"2409\", \"2410\", \"2411\", \"2412\", \"2413\", \"2414\", \"2415\", \"2454\", \"2416\", \"2452\", \"2453\", \"2455\", \"2456\", \"2459\", \"2457\", \"2458\", \"2460\", \"2461\", \"2462\", \"2463\", \"2464\"]\n",
    "\n",
    "\n",
    "tete_wb = list(map(int, tete_wb))\n",
    "tete_aga = list(map(int, tete_aga))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b910999-3ab4-4edc-9d5a-8c24601e38eb",
   "metadata": {},
   "source": [
    "# API Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac181a62-5d07-46b6-bd8d-f56419f7ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.oxfordeo.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3c618-8765-4366-a420-315d4b13b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpx.Client(base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4fdee-e8f9-4652-82fa-65cc85ec548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = client.post(\n",
    "    \"auth/token\",\n",
    "    data={\"username\": os.environ[\"API_USER\"], \"password\": os.environ[\"API_PASS\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8579a-1e8f-44ef-9f64-57d97d2b8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = json.loads(r.text)[\"access_token\"]\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3989414-2d25-4d8b-aa9f-07426b36bf91",
   "metadata": {},
   "source": [
    "# Get agricultural areas geoms from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298df819-d44f-4b43-a7f2-b9c67c003113",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = []\n",
    "for wb_id in tete_aga:\n",
    "    try:\n",
    "        r = client.get(\"aoi/\", params=dict(id=wb_id), headers=headers)\n",
    "        res = json.loads(r.text)\n",
    "        polygons.append(geometry.shape(res[\"features\"][0][\"geometry\"]))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f64afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unary_union(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bbox for all the ag areas\n",
    "box = unary_union(polygons).bounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5293bd6-f5d3-4758-8735-7e80074335d0",
   "metadata": {},
   "source": [
    "# Get Events from DB \n",
    "- Date range from 2019 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7722d23-d787-42b5-b9fa-34260117ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = \"2019-01-01\"\n",
    "end_datetime = \"2021-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97660cf-7bae-4b45-9146-6e55ae3c259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aga_results = []\n",
    "for aoi in tete_aga:\n",
    "    r = client.get(\n",
    "        \"events/\",\n",
    "        params=dict(\n",
    "            aoi_id=aoi,\n",
    "            start_datetime=start_datetime,\n",
    "            end_datetime=end_datetime,\n",
    "            limit=10000,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=60,\n",
    "    )\n",
    "    aga_results.extend(json.loads(r.text)[\"events\"])\n",
    "    \n",
    "wb_results = []\n",
    "for aoi in tete_wb:\n",
    "    r = client.get(\n",
    "        \"events/\",\n",
    "        params=dict(\n",
    "            aoi_id=aoi,\n",
    "            start_datetime=start_datetime,\n",
    "            end_datetime=end_datetime,\n",
    "            limit=10000,\n",
    "        ),\n",
    "        headers=headers,\n",
    "        timeout=60,\n",
    "    )\n",
    "    wb_results.extend(json.loads(r.text)[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyed_values(results, keyed_value, new_col):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.labels = df.labels.map(lambda x: x[0])\n",
    "    df[new_col] = df.keyed_values.apply(lambda x: x.get(keyed_value))\n",
    "    df = df.drop_duplicates(subset=[\"aoi_id\", \"datetime\"]).dropna()\n",
    "    df.datetime = pd.to_datetime(df.datetime)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae5e97-70c4-4b27-aedc-5ee4394cb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aga_df = get_keyed_values(aga_results, \"mean_value\", \"ndvi_mean\")\n",
    "wb_df = get_keyed_values(wb_results, \"water_pixels\", \"water_pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea852c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: We don't have water pixels for all the dates, we should run the predictions. \n",
    "# I'm not using water pixels predictions from now on to avoid problems.\n",
    "aga_df.datetime.min(), aga_df.datetime.max(), wb_df.datetime.min(), wb_df.datetime.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce18eb",
   "metadata": {},
   "source": [
    "# Get NDVI for given daterange\n",
    "- Filter results by date\n",
    "- Fill na values using forward fill (we don't an image for every single day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi=aga_df[(aga_df.datetime >= start_datetime) & (aga_df.datetime <= end_datetime)].groupby([\"datetime\"]).mean()[\"ndvi_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4defffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(start_datetime, end_datetime)\n",
    "ndvi = ndvi.reindex(idx)\n",
    "ndvi = ndvi.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592e287",
   "metadata": {},
   "source": [
    "# Get precipitation data from bucket\n",
    "- Data is stored in zarr with dimensions: latitude, longitude, step, member and time\n",
    "- step is synonym of \"days forecast\" (up to 215 days = 7 months). Shows acum TP (if we don't want acum, we can use df.diff)\n",
    "- members are different forecast models (up to 50). We can average them\n",
    "- time has a measure everymonth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "url = 'gs://oxeo-seasonal/tp'\n",
    "zx = xr.open_zarr(gcsfs.GCSMap(url)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea39c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x, min_y, max_x, max_y = box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6649335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "data = zx['tp'].sel({'time':slice(datetime.strptime(start_datetime, \"%Y-%m-%d\"),\n",
    "                                  datetime.strptime(end_datetime, \"%Y-%m-%d\")),\n",
    "                'latitude':slice(round(max_y),round(min_y)),\n",
    "                'longitude':slice(round(min_x),round(max_x))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b26bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9fceda",
   "metadata": {},
   "source": [
    "## Getting daily tp data\n",
    "We have monthly measures but for each month we have 215 days of forecast data. \n",
    "If we want to have a measure per day we have to:\n",
    "- query the forecasted data for the next 30 days of each month.\n",
    "- Get the average of all \"members\"\n",
    "- apply diff to df so we don't get the acum TP but single measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de84d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_tp(data, date_from, date_to):\n",
    "    day_range = pd.date_range(date_from, date_to,freq=\"D\")\n",
    "    day_range = day_range[day_range.day == 1]\n",
    "    days_per_month = pd.Series(data.sel(time=day_range).time.values).map(lambda x: pd.Period(x,freq=\"D\").days_in_month)\n",
    "    tp_per_day = []\n",
    "    for i,dpm in enumerate(days_per_month):\n",
    "        cum_tp = pd.Series(data.isel(time=i).mean(dim=[\"latitude\",\"longitude\"]).isel(step=slice(dpm)).mean(dim=\"member\").values)\n",
    "        cum_tp = cum_tp.diff().fillna(cum_tp)\n",
    "        tp_per_day.append(cum_tp)\n",
    "    flat_list = [item for sublist in tp_per_day for item in sublist]\n",
    "    return pd.Series(flat_list, index=pd.date_range(date_from, date_to))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd572e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_per_day = get_daily_tp(data, start_datetime, end_datetime)\n",
    "tp_per_day.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11341fc7",
   "metadata": {},
   "source": [
    "# Timeseries models\n",
    "We can start using some simple ARIMA models and try to predict NDVI. \n",
    "We start only using ndvi data and later we'll add weather data as an exogenous variable.\n",
    "\n",
    "Models:\n",
    "- Rolling 30D NDVI Model with Sarima\n",
    "- NDVI + Weather 30D using RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9769fc",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91978413",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ndvi.shape[0] - 215\n",
    "\n",
    "train=ndvi[:days]\n",
    "test=ndvi[days:]\n",
    "\n",
    "\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_ndvi = ndvi.rolling(\"30D\").mean()\n",
    "rolling_ndvi= rolling_ndvi[rolling_ndvi.index.day == 1]\n",
    "\n",
    "rolling_train = rolling_ndvi[:-7]\n",
    "rolling_test = rolling_ndvi[-7:]\n",
    "\n",
    "\n",
    "rolling_tp = tp_per_day.rolling(\"30D\").mean()\n",
    "rolling_tp= rolling_tp[rolling_tp.index.day == 1]\n",
    "\n",
    "rolling_tp_train = rolling_tp[:-7]\n",
    "rolling_tp_test = rolling_tp[-7:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee37d5",
   "metadata": {},
   "source": [
    "## NVDI Model with sarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scalecast\n",
    "from scalecast.Forecaster import Forecaster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(14,7)})\n",
    "\n",
    "\n",
    "f = Forecaster(y=rolling_ndvi,exog=rolling_tp,current_dates=rolling_ndvi.index)\n",
    "\n",
    "f.generate_future_dates(7) # 12-month forecast horizon\n",
    "f.set_test_length(.2) # 20% test set\n",
    "\n",
    "model_name = \"arima\"\n",
    "f.set_estimator(model_name) # set arima\n",
    "\n",
    "\n",
    "# Forecast\n",
    "f.manual_forecast(order=(1,1,0),seasonal_order=(1,1,1,12),call_me=model_name)\n",
    "\n",
    "# View test results\n",
    "f.plot_test_set(ci=True,models=model_name)\n",
    "plt.title('ARIMA Test-Set Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "# View forecast results\n",
    "f.plot(ci=True,models=model_name)\n",
    "plt.title('ARIMA Forecast Performance',size=14)\n",
    "plt.show()\n",
    "\n",
    "# See summary stats\n",
    "f.regr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffe2ff",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = -7 # shift in months. You can use -1 for 1 month forecast, -2 for 2 months...\n",
    "\n",
    "target_1m = rolling_ndvi.shift(shift)\n",
    "data = pd.DataFrame(rolling_ndvi)\n",
    "data[\"tp\"] = rolling_tp\n",
    "data[\"y\"] = target_1m\n",
    "data = data.dropna()\n",
    "data_train = data[:-7]\n",
    "data_test = data[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['ndvi_mean']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "model.fit(data_train[cols_to_use], data_train[\"y\"])\n",
    "# make a one-step prediction\n",
    "yhat = model.predict(data_test[cols_to_use])\n",
    "plt.plot(pd.Series(yhat, index=data_test.index),'--')\n",
    "plt.plot(data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['ndvi_mean', 'tp']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "model.fit(data_train[cols_to_use], data_train[\"y\"])\n",
    "# make a one-step prediction\n",
    "yhat = model.predict(data_test[cols_to_use])\n",
    "plt.plot(pd.Series(yhat, index=data_test.index),'--')\n",
    "plt.plot(data[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773b13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
